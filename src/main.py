"""Trump Speeches NLP Chatbot API - Production-Ready AI Platform

Comprehensive NLP and RAG platform for analyzing Trump rally speeches (2019-2020).
Features AI-powered Q&A with multiple LLM providers (Gemini, OpenAI, Claude), sentiment
analysis with FinBERT, semantic search, and advanced text analytics. Built with FastAPI,
ChromaDB, and LangChain.

Run with: uvicorn src.main:app --reload
"""

import logging
from contextlib import asynccontextmanager
from pathlib import Path

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles

from .api import chatbot_router, health_router, nlp_router
from .api.dependencies import (
    set_llm_service,
    set_nlp_service,
    set_rag_service,
    set_sentiment_analyzer,
    set_topic_service,
)
from .config.settings import get_settings
from .services import (
    EnhancedSentimentAnalyzer,
    NLPService,
    RAGService,
    TopicExtractionService,
    create_llm_provider,
)

# Get configuration
settings = get_settings()

# Configure logging based on settings
settings.setup_logging()
logger = logging.getLogger(__name__)


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Lifespan context manager for startup and shutdown events.

    Handles model loading on startup and cleanup on shutdown.
    """
    # Startup
    logger.info("=" * 70)
    settings.log_startup_info(logger)
    logger.info("=" * 70)

    # Initialize LLM service if configured
    llm_service = None
    if settings.is_llm_configured():
        try:
            logger.info(f"Initializing {settings.llm.provider.upper()} LLM service...")
            llm_service = create_llm_provider(settings)

            # Test connection
            if llm_service and llm_service.test_connection():
                logger.info("✓ LLM service initialized and tested successfully")
                set_llm_service(llm_service)
            else:
                logger.warning("⚠️  LLM connection test failed")
                llm_service = None
        except Exception as e:
            logger.error(f"✗ Failed to initialize LLM: {e}")
            llm_service = None
    else:
        logger.warning("⚠️  LLM not configured - RAG will use extraction-based answers")
        logger.warning("   Set LLM_API_KEY in .env file for AI-powered answers")

    # Load sentiment analysis model with LLM for contextual interpretation
    logger.info("Loading AI-powered sentiment analysis models...")
    try:
        sentiment_analyzer = EnhancedSentimentAnalyzer(
            sentiment_model=settings.models.sentiment_model_name,
            emotion_model=settings.models.emotion_model_name,
            llm_service=llm_service,
        )
        set_sentiment_analyzer(sentiment_analyzer)
        logger.info("✓ Sentiment analysis models loaded successfully")
    except Exception as e:
        logger.error(f"✗ Failed to load sentiment models: {e}")
        # Continue without model - endpoints will return errors

    # Initialize NLP service
    logger.info("Initializing NLP service...")
    try:
        nlp_service = NLPService()
        set_nlp_service(nlp_service)
        logger.info("✓ NLP service initialized")
    except Exception as e:
        logger.error(f"✗ Failed to initialize NLP service: {e}")

    # Initialize RAG service
    logger.info("Initializing RAG service...")
    try:
        rag_service = RAGService(
            collection_name=settings.rag.chromadb_collection_name,
            persist_directory=settings.rag.chromadb_persist_directory,
            embedding_model=settings.models.embedding_model_name,
            reranker_model=settings.models.reranker_model_name,
            chunk_size=settings.rag.chunk_size,
            chunk_overlap=settings.rag.chunk_overlap,
            llm_service=llm_service,
            use_reranking=settings.rag.use_reranking,
            use_hybrid_search=settings.rag.use_hybrid_search,
        )

        # Check if collection is empty and load documents if needed
        if rag_service.collection.count() == 0:
            logger.info("Loading documents into RAG service...")
            docs_loaded = rag_service.load_documents(settings.paths.speeches_directory)
            logger.info(f"✓ Loaded {docs_loaded} documents into RAG service")
        else:
            chunk_count = rag_service.collection.count()
            logger.info(f"✓ RAG service initialized with {chunk_count} existing chunks")

        set_rag_service(rag_service)

        # Initialize enhanced topic extraction service with shared embedding model and LLM
        logger.info("Initializing enhanced topic extraction service...")
        try:
            topic_service = TopicExtractionService(
                embedding_model=rag_service.embedding_model,  # Reuse RAG embeddings
                llm_service=llm_service,  # Reuse Gemini LLM
            )
            set_topic_service(topic_service)
            logger.info("✓ Enhanced topic extraction service initialized")
        except Exception as e:
            logger.error(f"✗ Failed to initialize topic service: {e}")

    except Exception as e:
        logger.error("=" * 70)
        logger.error("✗ CRITICAL: RAG service initialization failed!")
        logger.error(f"Error type: {type(e).__name__}")
        logger.error(f"Error message: {str(e)}")
        logger.error("=" * 70)
        logger.exception("Full traceback:")
        logger.error("=" * 70)
        logger.error("RAG endpoints will return 503. Check:")
        logger.error("  1. LLM_API_KEY is set and valid")
        logger.error(
            "  2. Data directories exist: ./data/chromadb, ./data/Donald Trump Rally Speeches"
        )
        logger.error("  3. Models can be downloaded (network access)")
        logger.error("  4. /diagnostics endpoint for detailed info")
        logger.error("=" * 70)
        # Continue without RAG - endpoints will return errors

    logger.info("=" * 70)
    logger.info("Application startup complete")
    logger.info("=" * 70)

    yield

    # Shutdown
    logger.info("Shutting down API...")


# Initialize FastAPI app with lifespan
app = FastAPI(
    title=settings.app_name,
    description="Production-ready NLP and RAG API for sentiment analysis, topic modeling, and conversational Q&A over Trump rally speeches. Built with FastAPI, ChromaDB, and Gemini.",
    version=settings.app_version,
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan,
)


# Add CORS middleware for frontend access
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.get_cors_origins(),
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# Mount static files
static_path = Path(__file__).parent / "static"
if static_path.exists():
    app.mount("/static", StaticFiles(directory=str(static_path)), name="static")


# Include routers
app.include_router(health_router)
app.include_router(nlp_router)
app.include_router(chatbot_router)


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "src.main:app",
        host=settings.api.host,
        port=settings.api.port,
        reload=settings.api.reload,
    )
